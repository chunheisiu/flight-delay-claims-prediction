{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flight Delay Claims Prediction â€“ Model Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the source code of the model prediction process of the Flight Delay Claims Prediction project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the notebook, please configure the source CSV file path and the output CSV file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_csv_path = 'REPLACE THIS WITH SOURCE CSV PATH'\n",
    "output_csv_path = 'REPLACE THIS WITH OUTPUT CSV PATH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_files_path = '../models/helper_files'\n",
    "best_model_path = '../models/model_flights_r2_37.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CSV file is first loaded as a pandas data frame, which allows it to be read and manipulated easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_original = pd.read_csv(source_csv_path, parse_dates=['flight_date'])\n",
    "flights = flights_original.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thought process of the following data cleaning procedures has been covered in the EDA notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill in missing airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.loc[flights.Airline.isnull(), 'Airline'] = flights.loc[flights.Airline.isnull(), 'flight_no'].str[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thought process of the following feature engineering procedures has been covered in the EDA notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Year, month, day, and day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights['flight_date_year'] = flights.flight_date.dt.year\n",
    "flights['flight_date_month'] = flights.flight_date.dt.month\n",
    "flights['flight_date_day'] = flights.flight_date.dt.day\n",
    "flights['flight_date_dow'] = flights.flight_date.dt.dayofweek\n",
    "\n",
    "flights.Week = flights.Week.astype('category')\n",
    "flights.flight_date_year = flights.flight_date_year.astype('category')\n",
    "flights.flight_date_month = flights.flight_date_month.astype('category')\n",
    "flights.flight_date_day = flights.flight_date_day.astype('category')\n",
    "flights.flight_date_dow = flights.flight_date_dow.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hong Kong public holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hk_holiday_data(years):\n",
    "    public_holidays = list()\n",
    "\n",
    "    for year in years:\n",
    "        holiday_url = f'https://www.gov.hk/en/about/abouthk/holiday/{year}.htm'\n",
    "        r = requests.get(holiday_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        holiday_dates = pd.read_html(r.text, skiprows=1)[0][1].apply(lambda x: f'{x} {year}')\n",
    "        holiday_dates = pd.to_datetime(holiday_dates, infer_datetime_format=True)\n",
    "        public_holidays.extend(holiday_dates)\n",
    "    \n",
    "    return public_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_years = flights.flight_date_year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_holidays = get_hk_holiday_data(flight_years)\n",
    "flights['is_public_holiday'] = np.where(flights.flight_date.isin(public_holidays), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hong Kong weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_data(years):\n",
    "    weather_list = list()\n",
    "\n",
    "    for year in years:\n",
    "        weather_url = f'https://www.hko.gov.hk/cis/dailyExtract/dailyExtract_{year}'\n",
    "        r = requests.get(weather_url, params={'y': year})\n",
    "        weather_data = r.json()['stn']['data']\n",
    "\n",
    "        for elem_month in weather_data:\n",
    "            month = elem_month['month']\n",
    "            day_data = elem_month['dayData'][:-2]\n",
    "            for elem_day in day_data:\n",
    "                day = elem_day[0]\n",
    "                mean_pressure = float(elem_day[1])\n",
    "                mean_temp = float(elem_day[3])\n",
    "                mean_dew_point = float(elem_day[5])\n",
    "                mean_humidity = float(elem_day[6])\n",
    "                mean_cloud = float(elem_day[7])\n",
    "                mean_rainfall = float(elem_day[8]) if elem_day[8] != 'Trace' else 0.0\n",
    "                weather_list.append({'flight_date': pd.to_datetime(f'{year}-{month:02}-{day}'),\n",
    "                                     'mean_pressure': mean_pressure, 'mean_temp': mean_temp, 'mean_dew_point': mean_dew_point,\n",
    "                                     'mean_humidity': mean_humidity, 'mean_cloud': mean_cloud, 'total_rainfall': mean_rainfall})\n",
    "\n",
    "    weather_df = pd.DataFrame(weather_list)\n",
    "    return weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = get_weather_data(flight_years)\n",
    "flights = pd.merge(flights, weather_df, on='flight_date', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert departure hour to category\n",
    "flights.std_hour = flights.std_hour.astype('category')\n",
    "\n",
    "# Drop unnecessary flight_date and flight_id column\n",
    "flights = flights.drop(columns=['flight_date', 'flight_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols_idx = [flights.columns.get_loc(c) for c in list(flights.select_dtypes(exclude=[np.number]).columns)]\n",
    "num_cols_idx = [flights.columns.get_loc(c) for c in list(flights.select_dtypes(include=[np.number]).columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(flights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_cat_variables(x, help_dict = None):\n",
    "    \"\"\"\n",
    "    Encodes a categorical variable.\n",
    "    The index 0 is left for values not in training.\n",
    "    \"\"\"\n",
    "    uniqs = np.unique(x)\n",
    "    if help_dict is None: help_dict = {v: k + 1 for k, v in enumerate(uniqs)}\n",
    "    levels = len(help_dict.keys()) + 1\n",
    "    x_t = np.array([help_dict.get(x_i, 0) for x_i in x])\n",
    "    return x_t, help_dict, levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataset(X, cat_ind, num_ind):\n",
    "    \"\"\"\n",
    "    Transform the dataset by encoding features.\n",
    "    \"\"\"\n",
    "    X_cat = X[:, cat_ind]\n",
    "    X_num = X[:, num_ind]\n",
    "\n",
    "    # Transform numerical variables\n",
    "    scaler = load(f'{helper_files_path}/scaler.joblib')\n",
    "    X_num = scaler.transform(X_num)\n",
    "\n",
    "    # Transform categorical variables\n",
    "    level_arr = [0] * X_cat.shape[1]\n",
    "    help_dict = load(f'{helper_files_path}/help_dict.joblib')\n",
    "    for i in range(X_cat.shape[1]):\n",
    "        level_arr[i] = len(help_dict[i].keys()) + 1\n",
    "        x, _, _ = encode_cat_variables(X_cat[:, i], help_dict[i])\n",
    "        X_cat[:, i] = x\n",
    "\n",
    "    X_cat = np.array(X_cat).astype(int)\n",
    "\n",
    "    return (X_cat, X_num), level_arr, scaler, help_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_cat, X_num), level_arr, _, _ = transform_dataset(X, cat_cols_idx, num_cols_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataSet(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset object for tabular data.\n",
    "    \"\"\"\n",
    "    def __init__(self, X_cat, X_num):\n",
    "        self.X_cat = X_cat\n",
    "        self.X_num = X_num\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_cat[index], self.X_num[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "X_ds = TabularDataSet(X_cat, X_num)\n",
    "X_dl = DataLoader(X_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularNet(nn.Module):\n",
    "    \"\"\"\n",
    "    2 layer fully connected neural network model.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_cont, num_cat, level_arr, hidden_dim=1000, hidden_dim2=1000):\n",
    "        super(TabularNet, self).__init__()\n",
    "        in_dim = num_cont + 2 * num_cat\n",
    "        self.embs = nn.ModuleList([nn.Embedding(level_arr[i], 2) for i in range(len(level_arr))])\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim2)\n",
    "        self.linear1 = nn.Linear(in_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim2)\n",
    "        self.linear3 = nn.Linear(hidden_dim2, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "                                  \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        x_cat = [self.embs[i](x_cat[:,i]) for i in range(x_cat.size(1))]\n",
    "        x_cat = torch.cat(x_cat, dim=1)\n",
    "        x_cat = self.dropout(x_cat)\n",
    "        x = torch.cat([x_cont, x_cat], dim=1)\n",
    "        x = self.bn1(F.relu(self.linear1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.bn2(F.relu(self.linear2(x)))\n",
    "        return self.linear3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(m, p): m.load_state_dict(torch.load(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cont = X_num.shape[1]\n",
    "num_cat = X_cat.shape[1]\n",
    "\n",
    "model = TabularNet(num_cont, num_cat, level_arr)\n",
    "load_model(model, best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dl):\n",
    "    model.eval()\n",
    "    delay_time = []\n",
    "    \n",
    "    for x1, x2 in dl:\n",
    "        out = model(x1.long(), x2.float()) #.cuda()\n",
    "        delay_time.extend(out.detach().numpy().flatten()) #.cpu()\n",
    "    \n",
    "    delay_time = np.array(delay_time)\n",
    "    is_claim = np.where(delay_time > 3, 800, 0)\n",
    "    return delay_time, is_claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_time, is_claim = predict(model, X_dl)\n",
    "flights_original['delay_time'] = delay_time\n",
    "flights_original['is_claim'] = is_claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_original.to_csv(output_csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
